{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Porto Seguro prediction problem (Kaggle)\n",
    "## Author : Mateus C. Pedrino\n",
    "\n",
    "The aim of this notebook is to provide a preliminary and exploratory analysis of Kaggle Porto Seguro prediction problem (available at : https://www.kaggle.com/c/porto-seguro-safe-driver-prediction), giving some tips of how to deal with missing and unbalanced data. After doing that, random forest will be tested and some discussions around it will be conducted considering accuracy and auc score results.\n",
    "\n",
    "I'd like to thank Rafael Alencar and Bert Carremans for theirs kernels, they were essential to perform the discussions in this notebook.\n",
    "\n",
    "It's also important to highlight that it's not the goal of this notebook to go deep in the solution, however it has achieved a successful auc score in the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>...</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "2  13       0          5              4          9              1   \n",
       "3  16       0          0              1          2              0   \n",
       "4  17       0          0              2          0              1   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin       ...        \\\n",
       "0              0              0              1              0       ...         \n",
       "1              0              0              0              1       ...         \n",
       "2              0              0              0              1       ...         \n",
       "3              0              1              0              0       ...         \n",
       "4              0              1              0              0       ...         \n",
       "\n",
       "   ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           9           1           5           8               0   \n",
       "1           3           1           1           9               0   \n",
       "2           4           2           7           7               0   \n",
       "3           2           2           4           9               0   \n",
       "4           3           1           1           3               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "2               1               1               0               1   \n",
       "3               0               0               0               0   \n",
       "4               0               0               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_train=pd.read_csv('train.csv', header=(0))\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check and deal with missing values\n",
    "\n",
    "Once missing values are indicated by \"-1\", we'll replace -1 for NaN in order to be able to use pandas to check the amount of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cp = df_train # Copy \n",
    "train_cp = train_cp.replace(-1, np.NaN)\n",
    "\n",
    "# Total missing values per feature\n",
    "total = train_cp.isnull().sum().sort_values(ascending=False) \n",
    "\n",
    "# Percentage of each feature that is missing\n",
    "percent = (train_cp.isnull().sum()/train_cp.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "# Concat both previous information\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ps_car_03_cat</th>\n",
       "      <td>411231</td>\n",
       "      <td>0.690898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_05_cat</th>\n",
       "      <td>266551</td>\n",
       "      <td>0.447825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_reg_03</th>\n",
       "      <td>107772</td>\n",
       "      <td>0.181065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_14</th>\n",
       "      <td>42620</td>\n",
       "      <td>0.071605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_07_cat</th>\n",
       "      <td>11489</td>\n",
       "      <td>0.019302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <td>5809</td>\n",
       "      <td>0.009760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_09_cat</th>\n",
       "      <td>569</td>\n",
       "      <td>0.000956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <td>216</td>\n",
       "      <td>0.000363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_01_cat</th>\n",
       "      <td>107</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <td>83</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_02_cat</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_11</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_03</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total   Percent\n",
       "ps_car_03_cat  411231  0.690898\n",
       "ps_car_05_cat  266551  0.447825\n",
       "ps_reg_03      107772  0.181065\n",
       "ps_car_14       42620  0.071605\n",
       "ps_car_07_cat   11489  0.019302\n",
       "ps_ind_05_cat    5809  0.009760\n",
       "ps_car_09_cat     569  0.000956\n",
       "ps_ind_02_cat     216  0.000363\n",
       "ps_car_01_cat     107  0.000180\n",
       "ps_ind_04_cat      83  0.000139\n",
       "ps_car_02_cat       5  0.000008\n",
       "ps_car_11           5  0.000008\n",
       "ps_car_12           1  0.000002\n",
       "ps_ind_03           0  0.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show missing data information\n",
    "\n",
    "missing_data.head(14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that ps_car_03_cat and ps_car_05_cat are both variables with lots of missing data (more than 40%), so it's plausible to remove this features from our analysis in order to avoid further problems.\n",
    "\n",
    "Let's take a better look in the other features with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>ps_car_14</th>\n",
       "      <th>ps_car_07_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_car_09_cat</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_car_01_cat</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_car_02_cat</th>\n",
       "      <th>ps_car_11</th>\n",
       "      <th>ps_car_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.718070</td>\n",
       "      <td>0.370810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.766078</td>\n",
       "      <td>0.388716</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.347275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.580948</td>\n",
       "      <td>0.294958</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.374166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.840759</td>\n",
       "      <td>0.365103</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.316070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ps_reg_03  ps_car_14  ps_car_07_cat  ps_ind_05_cat  ps_car_09_cat  \\\n",
       "0   0.718070   0.370810            1.0            0.0            0.0   \n",
       "1   0.766078   0.388716            1.0            0.0            2.0   \n",
       "2        NaN   0.347275            1.0            0.0            2.0   \n",
       "3   0.580948   0.294958            1.0            0.0            3.0   \n",
       "4   0.840759   0.365103            1.0            0.0            2.0   \n",
       "\n",
       "   ps_ind_02_cat  ps_car_01_cat  ps_ind_04_cat  ps_car_02_cat  ps_car_11  \\\n",
       "0            2.0           10.0            1.0            1.0        2.0   \n",
       "1            1.0           11.0            0.0            1.0        3.0   \n",
       "2            4.0            7.0            1.0            1.0        1.0   \n",
       "3            1.0            7.0            0.0            1.0        1.0   \n",
       "4            2.0           11.0            1.0            1.0        3.0   \n",
       "\n",
       "   ps_car_12  \n",
       "0   0.400000  \n",
       "1   0.316228  \n",
       "2   0.316228  \n",
       "3   0.374166  \n",
       "4   0.316070  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_missing=np.array(missing_data.index,dtype=str)\n",
    "features_missing=features_missing[2:13] # Labels of missing features\n",
    "train_cp[features_missing].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have 3 types of remaining missing features : \n",
    "\n",
    "- categorical (\"cat\" sufix);\n",
    "- continous : ps_reg_03, ps_car_12 and ps_car_14;\n",
    "- ordinal : neither categorical nor continous : ps_car_11.\n",
    "\n",
    "For these missing values, we can consider the following approaches : \n",
    "\n",
    "- categorical : replace back NaN for -1 and treat -1 as a new class;\n",
    "- continous : replace missing values for mean or median (we'll try mean first);\n",
    "- ordinal : replace missing values by mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595212, 59)\n",
      "(595212, 57)\n"
     ]
    }
   ],
   "source": [
    "# Remove 'ps_car_03_cat' and 'ps_car_05_cat' (over 40% of missing values)\n",
    "train_cp=train_cp.drop(['ps_car_03_cat','ps_car_05_cat'],axis=1)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(train_cp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we removed those two columns with more than 40% of missing values. Let's handle the other ones !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Former X_continous shape :  (595212, 3)\n",
      "Number of missing values in continous features :  150393 \n",
      "\n",
      "New X_continous shape :  (595212, 3)\n",
      "Still missing values in X_continous :  0\n"
     ]
    }
   ],
   "source": [
    "# Replace continous values by mean\n",
    "X_continous = np.array(train_cp[['ps_reg_03', 'ps_car_12', 'ps_car_14']],\\\n",
    "                       dtype = float)\n",
    "\n",
    "print('Former X_continous shape : ',X_continous.shape)\n",
    "print('Number of missing values in continous features : ',np.isnan(X_continous).sum(),'\\n')\n",
    "\n",
    "means = np.nanmean(X_continous, axis = 0) # Means of each feature\n",
    "for i in np.arange(0, X_continous.shape[0]):\n",
    "    for j in np.arange(0, X_continous.shape[1]):\n",
    "        if(np.isnan(X_continous[i,j]) == True):\n",
    "            X_continous[i,j] = means[j]\n",
    "            \n",
    "print('New X_continous shape : ',X_continous.shape)\n",
    "print('Still missing values in X_continous : ',np.isnan(X_continous).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, once the shape of X_continous hasn't changed and there is no more NaN, we can conclude that mean replacement was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Former X_ordinal shape :  (595212,)\n",
      "Number of missing values in ordinal feature :  5 \n",
      "\n",
      "New X_ordinal shape :  (595212,)\n",
      "Still missing values in X_ordinal :  0\n"
     ]
    }
   ],
   "source": [
    "# Replace ordinal feature by mode\n",
    "X_ordinal=np.array(train_cp['ps_car_11'],dtype = float)\n",
    "\n",
    "print('Former X_ordinal shape : ',X_ordinal.shape)\n",
    "print('Number of missing values in ordinal feature : ',np.isnan(X_ordinal).sum(),'\\n')\n",
    "\n",
    "from scipy import stats\n",
    "modes = stats.mode(X_ordinal,axis=0,nan_policy='omit').mode.item()\n",
    "\n",
    "for i in np.arange(0, X_ordinal.shape[0]):\n",
    "    if(np.isnan(X_ordinal[i]) == True):\n",
    "        X_ordinal[i] = modes\n",
    "        \n",
    "print('New X_ordinal shape : ',X_ordinal.shape)\n",
    "print('Still missing values in X_ordinal : ',np.isnan(X_ordinal).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, once the shape of X_ordinal hasn't changed and there is no more NaN, we can conclude that mode replacement was successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, once we've already dealed with continous and ordinal features, after replacing these features with the new ones (with mean and mode instead of NaN), the only remaining NaN will correspond to categorical features. So, we can replace them back to -1 and create this new class. \n",
    "\n",
    "So, first, let's replace !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Replacing continuous and ordinal missing features\n",
    "train_cp[['ps_reg_03','ps_car_12','ps_car_14']]=X_continous[:,0:3]\n",
    "train_cp['ps_car_11']=X_ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ps_car_07_cat</th>\n",
       "      <td>11489</td>\n",
       "      <td>0.019302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <td>5809</td>\n",
       "      <td>0.009760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_09_cat</th>\n",
       "      <td>569</td>\n",
       "      <td>0.000956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <td>216</td>\n",
       "      <td>0.000363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_01_cat</th>\n",
       "      <td>107</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <td>83</td>\n",
       "      <td>0.000139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_02_cat</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_04_cat</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total   Percent\n",
       "ps_car_07_cat   11489  0.019302\n",
       "ps_ind_05_cat    5809  0.009760\n",
       "ps_car_09_cat     569  0.000956\n",
       "ps_ind_02_cat     216  0.000363\n",
       "ps_car_01_cat     107  0.000180\n",
       "ps_ind_04_cat      83  0.000139\n",
       "ps_car_02_cat       5  0.000008\n",
       "ps_calc_20_bin      0  0.000000\n",
       "ps_ind_15           0  0.000000\n",
       "ps_car_04_cat       0  0.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking missing values in the replaced data frame\n",
    "\n",
    "# Total missing values per feature\n",
    "total_re = train_cp.isnull().sum().sort_values(ascending=False) \n",
    "\n",
    "# Percentage of each feature that is missing\n",
    "percent_re = (train_cp.isnull().sum()/train_cp.isnull().count()).sort_values(ascending=False)\n",
    "\n",
    "# Concat both previous information\n",
    "missing_data_re = pd.concat([total_re, percent_re], axis=1, keys=['Total', 'Percent'])\n",
    "\n",
    "missing_data_re.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the only missing values correspond to categorical features, that's why we can do the direct NaN replacement for -1 again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cp=train_cp.replace(np.NaN, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ps_car_07_cat</th>\n",
       "      <td>11489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <td>5809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_09_cat</th>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_01_cat</th>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_02_cat</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_ind_15</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ps_car_04_cat</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total\n",
       "ps_car_07_cat   11489\n",
       "ps_ind_05_cat    5809\n",
       "ps_car_09_cat     569\n",
       "ps_ind_02_cat     216\n",
       "ps_car_01_cat     107\n",
       "ps_ind_04_cat      83\n",
       "ps_car_02_cat       5\n",
       "ps_calc_20_bin      0\n",
       "ps_ind_15           0\n",
       "ps_car_04_cat       0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of -1 to see if they are equal to the number of NaN in missing_data_re\n",
    "total_minus1=pd.DataFrame((train_cp==-1).sum().sort_values(ascending=False),columns=['Total'])\n",
    "total_minus1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the number of -1 is equal to previous number of NaN in categorical features, that's why the missing values in training features is solved for now. One more simple thing that can be performed is to check duplicated in training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping duplicates :  (595212, 57)\n",
      "After dropping duplicates :  (595212, 57)\n"
     ]
    }
   ],
   "source": [
    "print('Before dropping duplicates : ',train_cp.shape)\n",
    "\n",
    "# Dropping duplicates\n",
    "train_cp = train_cp.drop_duplicates()\n",
    "\n",
    "print('After dropping duplicates : ',train_cp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, once the training set shape hasn't changed, we can conclude that there were no duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with unbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(573518, 57)\n",
      "(21694, 57)\n"
     ]
    }
   ],
   "source": [
    "# Divide by class\n",
    "df_class_0 = train_cp[train_cp['target'] == 0]\n",
    "df_class_1 = train_cp[train_cp['target'] == 1]\n",
    "\n",
    "print(df_class_0.shape)\n",
    "print(df_class_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the number of instances with target 0 is far bigger than the number of instances with target 1. There is basically two simple ways to deal with this : oversampling and undersampling. Once we are providing only a preliminary approach for this problem, we won't explore the resampling problem further. I've already tried basic over and undersamling and it didn't work well, so we can use SMOTE oversampling from imblearn, which basic oversamples the minority data creating similar data randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using random oversampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# id isn't important for prediction and target is the output feature\n",
    "aux_data=train_cp # Avoid changes in original data frame (which is already a copy)\n",
    "aux_data=aux_data.drop(aux_data.columns[0],axis=1)\n",
    "labels=list(aux_data.columns) # get features labels without id\n",
    "X=np.array(aux_data.drop(labels[0], axis = 1)) #input data\n",
    "Y=np.array(aux_data[labels[0]],dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = SMOTE(ratio='minority')\n",
    "X_res, y_res = ros.fit_resample(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split \"training\" data into real training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "p=0.7\n",
    "train_x, test_x, train_y, test_y = train_test_split(X_res, y_res, test_size = 1-p, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171855"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(test_y==1).sum()\n",
    "#train_x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features=5, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=3, max_features=5)\n",
    "model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.8734768722883023\n",
      "171855\n",
      "172256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred_y=model.predict(test_x)\n",
    "scr=accuracy_score(pred_y,test_y)\n",
    "\n",
    "print('Accuracy : ',scr)\n",
    "print((test_y==1).sum())\n",
    "print((test_y==0).sum()) # Balanced classes !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, we have to take a lot of care with accuracy, specially with unbalanced data. Accuracy only treat the ratio of total amount of correct cases divided by the total amount of cases. If we have, for instance, 90% of class 0 and 10% of class 1 in test set and our model memorizes the answer \"class 0\" because of unbalanced data, our accuracy will be high, but we'll be missing all class 1 data. \n",
    "\n",
    "In order to be able to realize this fenomenon we might use confusion matrix or auc_score. Now that we balanced data (we have almost the same amount of class 1 and 0 in the test set as showed above), the accuracy score won't be so dangerous. However, it's a good practice to look at auc_score if you want to avoid misunderstandings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.8739256982987567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(pred_y, test_y)\n",
    "\n",
    "print('AUC score:',auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we had a high AUC score for our resampled data, so I think the aim of this preliminary analysis was sucessfully achieved.\n",
    "\n",
    "Varying random forest parameters or testing XGBoost (also varying parameters) might be a good way to increase auc score and conduct to better results. \n",
    "\n",
    "Thanks for your attention !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
